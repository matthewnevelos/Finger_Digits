{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. How to run\n",
    "\n",
    "- Open anaconda prompt to this directory\n",
    "\n",
    "- Use `conda activate endg411` \n",
    "- - If you have an environment with PyTorch CUDA installed please use. Everything will still work but there are features only available with CUDA\n",
    "- Switch to this directory\n",
    "- Run `python \"Finger Digit Trainer.ipynb\"\n",
    "\n",
    "### Capture Window:\n",
    "- Browse for train/valid folder\n",
    "- Take pictures using the `save` button or using `burst`\n",
    "\n",
    "\n",
    "### Training Window:\n",
    "- Select desired parameters\n",
    " - - directory\n",
    " - - model\n",
    " - - confusion matrix\n",
    " - - etc...\n",
    "- Generate code\n",
    "- Copy and paste code into [Training Notebook](Finger%20Digit%20Trainer.ipynb)\n",
    "- Train model\n",
    "\n",
    "\n",
    "### Production Window:\n",
    "- Select model\n",
    "- Real time prediction (with CUDA if enabled)\n",
    "- Choose a CSV file and save the actual vs. predicted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "Describe the approach chosen, reason for choosing it and how you implemented it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Combined a2, a3, a4 into one coherant program with added features for a more streamline development\n",
    "\n",
    "2) Used \n",
    "- AlexNet\n",
    "- DenseNet121\n",
    "- EfficientNet_b0\n",
    "- EfficientNet_b1\n",
    "- GoogleNet\n",
    "- MnasNet0_5\n",
    "- MnasNet1_0\n",
    "- MobileNetV2\n",
    "- MobileNet_v3_small\n",
    "- ResNet18\n",
    "- ResNet50\n",
    "- SqueezeNet1_0\n",
    "- SqueezeNet1_1\n",
    "- VGG13_bn\n",
    "- VGG16 \\\n",
    "On the first dataset `digits_1.0` to find the most accurate model\\\n",
    "`DenseNet121` was the most accurate model with an error rate of `0.67%`\n",
    "\n",
    "3) Trained DenseNet on the OneDrive link of photos\n",
    "\n",
    "4) Took more photos myself with different attributes such as \n",
    "- Different lighting\n",
    "- Different camera\n",
    "- wearing gloves\n",
    "- etc.\n",
    "5) Again used DenseNet to train a model based on the updated dataset\n",
    "\n",
    "<strike> 6)If time allows, add a CAM window to the program and add an analysis using it</strike>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model training and Results\n",
    "Any code to train a model and produce results or a reference to the notebook/code file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See [Notebook](Finger%20Digit%20Trainer.ipynb) to train models\n",
    "\n",
    "## digit_1.0\n",
    "See [NOTE](Projects\\digits_1.0\\NOTE.txt) for the types of pictures covered in this dataset\n",
    "\n",
    "### Training data\n",
    "| Model           | Accuracy | Training Time           |\n",
    "|-----------------|----------|-------------------------|\n",
    "| AlexNet         | 0.840    | 0 hours, 3 min, 31 sec  |\n",
    "| DenseNet121     | 0.993    | 2 hours, 44 min, 39 sec |\n",
    "| EfficientNet_b0 | 0.857    | 1 hours, 54 min, 5 sec  |\n",
    "| GoogleNet       | 0.790    | 0 hours, 6 min, 43 sec  |\n",
    "| MobileNet_v3    | 0.713    | 0 hours, 3 min, 35 sec  |\n",
    "| ResNet18        | 0.953    | 0 hours, 5 min, 10 sec  |\n",
    "| ResNet50        | 0.967    | 1 hours, 10 min, 24 sec |\n",
    "| SqueezeNet1_0   | 0.900    | 0 hours, 4 min, 42 sec  |\n",
    "| SqueezeNet1_1   | 0.930    | 0 hours, 3 min, 25 sec  |\n",
    "| VGG13_bn        | 0.923    | 3 hours, 4 min, 54 sec  |\n",
    "\n",
    "The lowest performing models are the quicker models however, the quickest models are not the worst models. \n",
    "SqueezeNet1_1 is the fastest model of the bunch and scored one of the highest accuracies at 93%\n",
    "\n",
    "DenseNet is by a good margin the best performing model at 99.3% unfortunatly that comes at the cost of nearly 3 hours\n",
    "\n",
    "![digit_1.0 DenseNet121 Confusion Matrix](Projects\\digits_1.0\\results\\DenseNet121.png)\n",
    "\n",
    "See [DenseNet Results](Projects\\digits_1.0\\models\\DenseNet121.txt) for data about training\n",
    "\n",
    "\n",
    "\n",
    "## class_digits\n",
    "This dataset contains the majority of photos from the OneDrive folder. Folders which did not follow the same structure were deleted.\n",
    "6543 training pictures and 1690 validation photos were used\n",
    "\n",
    "The training validation score was 96.4%, 3% lower than my first dataset. I believe this to be largely due to more careless pictures in the data. \\\n",
    "While going through some of the photos, I noticed a couple rotten eggs. For example, a blank photo. I do not know the full extent of poor photos like this but it would explani why a dataset 4x the amount of photos performs worse.\n",
    "\n",
    "![class_digits DenseNet121 Confusion Matrix](Projects\\class_digits\\results\\DenseNet121.png)\n",
    "\n",
    "See [DenseNet Results](Projects\\class_digits\\models\\DenseNet121.txt) for data about training\n",
    "\n",
    "\n",
    "\n",
    "## digits_2.0\n",
    "See [NOTE](Projects\\digits_2.0\\NOTE.txt) for the types of pictures covered in this dataset\\\n",
    "This dataset is an addition to the first\\\n",
    "These photos were more harder to classify by design. I wore a thick black glove which made it a lot trickier to see which fingers are being held up. In addition, pictures were taken in a room dimly lit by RGB lights, this gave the whole picture a tint. When the lights were yellow, my hands blended into my face and made it hard to differentiate the fingers\n",
    "\n",
    "Unfortunatly, time did not permit to use DenseNet121 for the training of this dataset. Every time I thought my code was bullet proof, I would run all the models expecting to come back to see them be all trained, but would see a nice error message which has been sitting at an idle computer for the whole day. Because of the time constraint, I used the ResNet18 architecture which was the 3rd highest scoring model. It was able to train the 3,000 photos in just 12 minutes\n",
    "\n",
    "Because the hard dataset and using an inferior architecture, the model only scored an accuracy of 85% Certainly still good all things considered but not as robust as I had hoped for\n",
    "\n",
    "![digits_2.0 ResNet18 Confusion Matrix](Projects\\digits_2.0\\results\\ResNet18.png)\n",
    "\n",
    "See [DenseNet Results](Projects\\digits_2.0\\models\\ResNet18.txt) for data about training\n",
    "\n",
    "\n",
    "Of all the models I have tested, they always have a problem when holding up 3 fingers, perhaps this has something to do with how the base architecture is laid out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Summary and Conclusion\n",
    "Summarize your new results and state your a3 and a4 results.\n",
    "\n",
    "Conclusion: How large is the improvement in the performance of the classifier due to the approach chosen? Include your interpretation why it worked (or did not work).\n",
    "\n",
    "The accuracy from a3 was 93.3%\n",
    "\n",
    "After changing to DenseNet121, the accuracy went to 99.3% \\\n",
    "A 6% jump when we are already in the 90's is very significant\n",
    "\n",
    "When using the class dataset, the accuracy fell to 94.6% \\\n",
    "This is still a highly accurate model, using different peoples pictures makes the model more robust. I cannot make it account for different skin tones and such\n",
    "\n",
    "Then, I took more tricky photos and switched back to ResNet 18. The accuracy fell to 85% \\\n",
    "Although this seemed to make the model worse, stressing it in this way improved how it performed in the majority of cases. Playing around with it, it felt more accurate where the initial resnet model failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Reflection\n",
    "Include a sentence or two about\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "\n",
    "while working on this assignment.\n",
    "\n",
    "I took a more holistic approach to this assignment. Redoing all previous assignments into one big package. Although looking back on it, I feel like I wasted a lot of time dealing with tkinter stuff which is more in the scope of ENDG311, I feel better as a programmer in a whole. So often programming assignments are so narrow in scope you don't get to understand what its like to do the whole program. \n",
    "\n",
    "In all, I think I have a pretty good understanding about the working of AI models and where to look when things go wrong.\n",
    "\n",
    "I am happy with my results and do plan on continuing them to get more accurate models\n",
    "\n",
    "# Cheers, happy summer!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
