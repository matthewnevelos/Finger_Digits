{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit AI Trainer\n",
    "#### How-to:\n",
    "- Paste function into last cell\n",
    "- Run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastai.vision.all import *\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def summary(model, input_size, batch_size=-1, device=\"cuda\"):\n",
    "# Copied from torchsummary\n",
    "    def register_hook(module):\n",
    "\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            summary[m_key][\"input_shape\"][0] = batch_size\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                summary[m_key][\"output_shape\"] = [\n",
    "                    [-1] + list(o.size())[1:] for o in output\n",
    "                ]\n",
    "            else:\n",
    "                summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                summary[m_key][\"output_shape\"][0] = batch_size\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "        if (\n",
    "            not isinstance(module, nn.Sequential)\n",
    "            and not isinstance(module, nn.ModuleList)\n",
    "            and not (module == model)\n",
    "        ):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    device = device.lower()\n",
    "    assert device in [\n",
    "        \"cuda\",\n",
    "        \"cpu\",\n",
    "    ], \"Input device is not valid, please specify 'cuda' or 'cpu'\"\n",
    "\n",
    "    if device == \"cuda\" and torch.cuda.is_available():\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    # multiple inputs to the network\n",
    "    if isinstance(input_size, tuple):\n",
    "        input_size = [input_size]\n",
    "\n",
    "    # batch_size of 2 for batchnorm\n",
    "    x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\n",
    "    # print(type(x[0]))\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "\n",
    "    # make a forward pass\n",
    "    # print(x.shape)\n",
    "    model(*x)\n",
    "\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    total_params = 0\n",
    "    total_output = 0\n",
    "    trainable_params = 0\n",
    "    for layer in summary:\n",
    "        # input_shape, output_shape, trainable, nb_params\n",
    "        line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "            layer,\n",
    "            str(summary[layer][\"output_shape\"]),\n",
    "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "        )\n",
    "        total_params += summary[layer][\"nb_params\"]\n",
    "        total_output += np.prod(summary[layer][\"output_shape\"])\n",
    "        if \"trainable\" in summary[layer]:\n",
    "            if summary[layer][\"trainable\"] == True:\n",
    "                trainable_params += summary[layer][\"nb_params\"]\n",
    "\n",
    "    # assume 4 bytes/number (float on cuda).\n",
    "    total_input_size = abs(np.prod(input_size) * batch_size * 4. )\n",
    "    total_output_size = abs(2. * total_output * 4. )  # x2 for gradients\n",
    "    total_params_size = abs(total_params.numpy() * 4.)\n",
    "    estimated_size = total_params_size + total_output_size + total_input_size\n",
    "\n",
    "    # total_size_str = \"Estimated Total Size (MB): %0.2f\" % total_size\n",
    "    return estimated_size\n",
    "\n",
    "def format_elapsed_time(start_time, end_time):\n",
    "    # Calculate the time difference in seconds\n",
    "    delta_time = end_time - start_time\n",
    "\n",
    "    # Convert to minutes and hours if necessary\n",
    "    if delta_time >= 3600:  # If delta_time is greater than or equal to 1 hour\n",
    "        hours = int(delta_time // 3600)\n",
    "        delta_time %= 3600\n",
    "    else:\n",
    "        hours = 0\n",
    "\n",
    "    if delta_time >= 60:  # If delta_time is greater than or equal to 1 minute\n",
    "        minutes = int(delta_time // 60)\n",
    "        delta_time %= 60\n",
    "    else:\n",
    "        minutes = 0\n",
    "\n",
    "    seconds = delta_time  # Remaining time in seconds\n",
    "    formatted_seconds = f\"{seconds:.2f}\"  # Format seconds with 2 decimal places\n",
    "\n",
    "    # Construct and return the formatted string\n",
    "    return f\"{hours} hours, {minutes} minutes, {formatted_seconds} seconds\"\n",
    "\n",
    "def save_confusion_matrix(interp, pic_path, cmap:str=\"Blues\"):\n",
    "    title = \"Confusion Matrix\"\n",
    "    \"Plot the confusion matrix, with `title` and using `cmap`.\"\n",
    "    # This function is mainly copied from the sklearn docs\n",
    "    cm = interp.confusion_matrix()\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(interp.vocab))\n",
    "    plt.xticks(tick_marks, interp.vocab, rotation=90)\n",
    "    plt.yticks(tick_marks, interp.vocab, rotation=0)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        coeff = f'{cm[i, j]}'\n",
    "        plt.text(j, i, coeff, horizontalalignment=\"center\", verticalalignment=\"center\", color=\"white\"\n",
    "                    if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    ax = fig.gca()\n",
    "    ax.set_ylim(len(interp.vocab)-.5,-.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.grid(False)\n",
    "    fig.savefig(pic_path)\n",
    "\n",
    "def train_model(digit_folder=\"Projects/digit/digits\", batch_size=32, epochs=12, seed=69, lr=3e-3, model_output=\"Projects/digit/models.pkl\", save_conf=False, conf_out='None', base_model=\"resnet18\"):\n",
    "    # Logging\n",
    "    torch.cuda.empty_cache()\n",
    "    log_name = model_output.replace(\".pkl\", \".txt\")\n",
    "    logging.getLogger().handlers = []\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    file_handler = logging.FileHandler(log_name)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', '%H:%M:%S')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logging.getLogger().addHandler(file_handler)\n",
    "    with open(log_name, 'w'):\n",
    "        pass\n",
    "    logging.info('Logger setup')\n",
    "    \n",
    "    # Setup device\n",
    "    available = torch.cuda.is_available()\n",
    "    logging.info(f'CUDA: {available}')\n",
    "    device = torch.device('cuda' if available else 'cpu')\n",
    "    logging.info(f\"Device: {torch.cuda.get_device_name(device)}\")\n",
    "\n",
    "    model_map = {\n",
    "\n",
    "        'alexnet': models.alexnet,\n",
    "        'densenet121': models.densenet121,\n",
    "        'densenet161': models.densenet161,\n",
    "        'densenet201': models.densenet201,\n",
    "        'efficientnet_b0': models.efficientnet_b0,\n",
    "        'efficientnet_b1': models.efficientnet_b1,\n",
    "        'googlenet': models.googlenet,\n",
    "        'inception_v3': models.inception_v3,\n",
    "        'mnasnet0_5': models.mnasnet0_5,\n",
    "        'mnasnet1_0': models.mnasnet1_0,\n",
    "        'mnasnet0_75': models.mnasnet0_75,\n",
    "        'mnasnet1_3': models.mnasnet1_3,\n",
    "        'mobilenetV2': models.mobilenet_v2,\n",
    "        'mobilenet_v3_small': models.mobilenet_v3_small,\n",
    "        'resnet18': models.resnet18,\n",
    "        'resnet34': models.resnet34,\n",
    "        'resnet50': models.resnet50,\n",
    "        'squeezenet1_0': models.squeezenet1_0,\n",
    "        'squeezenet1_1': models.squeezenet1_1,\n",
    "        'vgg13_bn': models.vgg13_bn,\n",
    "        'vgg16': models.vgg16,\n",
    "        'vgg19_bn': models.vgg19_bn,\n",
    "    }\n",
    "\n",
    "\n",
    "    arch = model_map[base_model]\n",
    "\n",
    "    logging.info(f'Base model architecture: {base_model}')\n",
    "\n",
    "    # Load data, set seed, augment training photos\n",
    "    set_seed(seed)\n",
    "\n",
    "    logging.info(f'Seed: {seed}')\n",
    "\n",
    "    fingers = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock),\n",
    "        get_items=get_image_files,\n",
    "        splitter=GrandparentSplitter(),\n",
    "        get_y=parent_label,\n",
    "        batch_tfms=aug_transforms(mult = 1.5,max_zoom=1.))\n",
    "    \n",
    "    logging.info(f'DataBlock created')\n",
    "\n",
    "    dls = fingers.dataloaders(digit_folder, batch_size=batch_size)\n",
    "\n",
    "    logging.info(f'DataLoader created')\n",
    "\n",
    "    # Create classifier\n",
    "    learn = vision_learner(dls, arch, metrics=error_rate, lr=lr)\n",
    "    learn.model.to(device)\n",
    "\n",
    "    logging.info(f'Learner created on {device}')\n",
    "\n",
    "    logging.info(f'Training started: \\n\\tNumber of epochs = {epochs} \\n\\tBatch size = {batch_size} \\n\\tLearning rate = {lr}')\n",
    "    time1 = time.time()\n",
    "\n",
    "    # Check estimated memory usage\n",
    "    device_properties = torch.cuda.get_device_properties(0)\n",
    "    device_memory = device_properties.total_memory\n",
    "    logging.info(f\"Device memory (MB): {device_memory / 1024**2:.2f}\")\n",
    "    try:\n",
    "        est_mem = summary(arch().cuda(), (3, 480, 640), batch_size=batch_size)\n",
    "        if est_mem > device_memory:\n",
    "            logging.info(f\"Estimated Total Size (MB): {est_mem / 1024**2:.2f}\")\n",
    "            logging.warning(\"Estimated memory usage is larger than device's memory\")\n",
    "    except:\n",
    "        logging.warning(\"Could not estimate estimated memory usage\")\n",
    "\n",
    "\n",
    "    # Train classifier\n",
    "    learn.fine_tune(epochs)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    time2 = time.time()\n",
    "\n",
    "    dt = format_elapsed_time(time1, time2)\n",
    "\n",
    "    logging.info(f'Training finished \\n\\tTime taken = {dt}')\n",
    "\n",
    "    # Analyze classifier\n",
    "    if save_conf:\n",
    "        interp = ClassificationInterpretation.from_learner(learn)\n",
    "        save_confusion_matrix(interp, conf_out)\n",
    "        logging.info(f'Confusion matrix: \\n{interp.confusion_matrix()}')\n",
    "\n",
    "    # Accuracy score\n",
    "    preds, targets = learn.get_preds(dl=dls.valid)\n",
    "    acc = accuracy_score(targets.numpy(), np.argmax(preds, axis=1))\n",
    "    logging.info(f'Validation accuracy = {acc}')\n",
    "\n",
    "    # Export model\n",
    "    # Check if file name ends in .pkl\n",
    "    if not model_output.endswith(\".pkl\"):\n",
    "            model_output += \".pkl\"\n",
    "\n",
    "    learn.export(fname=model_output)\n",
    "\n",
    "    # Close logging\n",
    "    logging.info(\"Exiting logger\")\n",
    "    file_handler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paste code into cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: train_model(save_conf=False, epochs=0, base_model=\"vgg16\", batch_size=32)\n",
    "train_model(save_conf=False, epochs=0, base_model=\"resnet18\", batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda411",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
