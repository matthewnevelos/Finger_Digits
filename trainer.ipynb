{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit AI Trainer\n",
    "#### How-to:\n",
    "- Paste function into last cell\n",
    "- Run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastai.vision.all import *\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def format_elapsed_time(start_time, end_time):\n",
    "    # Calculate the time difference in seconds\n",
    "    delta_time = end_time - start_time\n",
    "\n",
    "    # Convert to minutes and hours if necessary\n",
    "    if delta_time >= 3600:  # If delta_time is greater than or equal to 1 hour\n",
    "        hours = int(delta_time // 3600)\n",
    "        delta_time %= 3600\n",
    "    else:\n",
    "        hours = 0\n",
    "\n",
    "    if delta_time >= 60:  # If delta_time is greater than or equal to 1 minute\n",
    "        minutes = int(delta_time // 60)\n",
    "        delta_time %= 60\n",
    "    else:\n",
    "        minutes = 0\n",
    "\n",
    "    seconds = delta_time  # Remaining time in seconds\n",
    "    formatted_seconds = f\"{seconds:.2f}\"  # Format seconds with 2 decimal places\n",
    "\n",
    "    # Construct and return the formatted string\n",
    "    return f\"{hours} hours, {minutes} minutes, {formatted_seconds} seconds\"\n",
    "\n",
    "def save_confusion_matrix(interp, pic_path, cmap:str=\"Blues\"):\n",
    "    title = \"Confusion Matrix\"\n",
    "    \"Plot the confusion matrix, with `title` and using `cmap`.\"\n",
    "    # This function is mainly copied from the sklearn docs\n",
    "    cm = interp.confusion_matrix()\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(interp.vocab))\n",
    "    plt.xticks(tick_marks, interp.vocab, rotation=90)\n",
    "    plt.yticks(tick_marks, interp.vocab, rotation=0)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        coeff = f'{cm[i, j]}'\n",
    "        plt.text(j, i, coeff, horizontalalignment=\"center\", verticalalignment=\"center\", color=\"white\"\n",
    "                    if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    ax = fig.gca()\n",
    "    ax.set_ylim(len(interp.vocab)-.5,-.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.grid(False)\n",
    "    fig.savefig(pic_path)\n",
    "\n",
    "def train_model(digit_folder=\"pics/digits\", batch_size=32, epochs=12, seed=69, lr=3e-3, model_output=\"models/test1.pkl\", save_conf=False, conf_out='None', base_model=\"resnet18\"):\n",
    "    # Logging\n",
    "    log_name = model_output.replace(\".pkl\", \".txt\")\n",
    "    logging.getLogger().handlers = []\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    file_handler = logging.FileHandler(log_name)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', '%H:%M:%S')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logging.getLogger().addHandler(file_handler)\n",
    "    with open(log_name, 'w'):\n",
    "        pass\n",
    "    logging.info('Logger setup')\n",
    "    \n",
    "    # Setup device\n",
    "    available = torch.cuda.is_available()\n",
    "    logging.info(f'CUDA: {available}')\n",
    "    device = torch.device('cuda' if available else 'cpu')\n",
    "    logging.info(f\"Device: {torch.cuda.get_device_name(device)}\")\n",
    "\n",
    "    model_map = {\n",
    "    'resnet18': models.resnet18,\n",
    "    'resnet34': models.resnet34,\n",
    "    'resnet50': models.resnet50,\n",
    "    'resnet101': models.resnet101,\n",
    "    'resnet152': models.resnet152,\n",
    "    'resnext50_32x4d': models.resnext50_32x4d,\n",
    "    'resnext101_32x8d': models.resnext101_32x8d,\n",
    "    'resnext101_64x4d': models.resnext101_64x4d,}\n",
    "\n",
    "    arch = model_map[base_model]\n",
    "\n",
    "    logging.info(f'Base model architecture: {base_model}')\n",
    "\n",
    "    # Load data, set seed, augment training photos\n",
    "    set_seed(seed)\n",
    "\n",
    "    logging.info(f'Seed: {seed}')\n",
    "\n",
    "    fingers = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock),\n",
    "        get_items=get_image_files,\n",
    "        splitter=GrandparentSplitter(),\n",
    "        get_y=parent_label,\n",
    "        batch_tfms=aug_transforms(mult = 1.5,max_zoom=1.))\n",
    "    \n",
    "    logging.info(f'DataBlock created')\n",
    "\n",
    "    dls = fingers.dataloaders(digit_folder, batch_size=batch_size)\n",
    "\n",
    "    logging.info(f'DataLoader created')\n",
    "\n",
    "    # Create classifier\n",
    "    learn = vision_learner(dls, arch, metrics=error_rate, lr=lr)\n",
    "    learn.model.to(device)\n",
    "\n",
    "    logging.info(f'Learner created on {device}')\n",
    "\n",
    "    logging.info(f'Training started: \\n\\tNumber of epochs = {epochs} \\n\\tBatch size = {batch_size} \\n\\tLearning rate = {lr}')\n",
    "    time1 = time.time()\n",
    "\n",
    "    # Train classifier\n",
    "    learn.fine_tune(epochs)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    time2 = time.time()\n",
    "\n",
    "    dt = format_elapsed_time(time1, time2)\n",
    "\n",
    "    logging.info(f'Training finished \\n\\tTime taken = {dt}')\n",
    "\n",
    "    # Analyze classifier\n",
    "    if save_conf:\n",
    "        interp = ClassificationInterpretation.from_learner(learn)\n",
    "        save_confusion_matrix(interp, conf_out)\n",
    "        logging.info(f'Confusion matrix: \\n{interp.confusion_matrix()}')\n",
    "\n",
    "    # Accuracy score\n",
    "    preds, targets = learn.get_preds(dl=dls.valid)\n",
    "    acc = accuracy_score(targets.numpy(), np.argmax(preds, axis=1))\n",
    "    logging.info(f'Validation accuracy = {acc}')\n",
    "\n",
    "    # Export model\n",
    "    # Check if file name ends in .pkl\n",
    "    if not model_output.endswith(\".pkl\"):\n",
    "            model_output += \".pkl\"\n",
    "\n",
    "    learn.export(fname=model_output)\n",
    "\n",
    "    # Close logging\n",
    "    logging.info(\"Exiting logger\")\n",
    "    file_handler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paste code into cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: train_model(save_conf=True, conf_out=\"models/test1.png\", epochs=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda411",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
